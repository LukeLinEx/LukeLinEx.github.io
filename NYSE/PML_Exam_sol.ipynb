{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import time\n",
    "# import random\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# adjusted = pd.read_csv('./input/prices-split-adjusted.csv')\n",
    "# fundamentals = pd.read_csv('./input/fundamentals.csv', index_col=0)\n",
    "# securities = pd.read_csv('./input/securities.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "The dataset  we will be using in this  exam is adapted from <a href=https://www.kaggle.com/dgawlik/nyse target=_blank>New York Stock Exchange</a>, where the original raw data can be found."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prob 1. Redundancy\n",
    "\n",
    "Among the columns in the data frame <a href=https://graderdata.s3.amazonaws.com/securities.txt target=_blank>securities</a>, one of them would be helpless as an independent variable for any kind of supervised learning. Which one is it and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SEC filings']\n",
      "\n",
      "\n",
      "0    reports\n",
      "1    reports\n",
      "2    reports\n",
      "3    reports\n",
      "4    reports\n",
      "Name: SEC filings, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "securities = pd.read_csv('https://graderdata.s3.amazonaws.com/securities.csv')\n",
    "\n",
    "### Your code here\n",
    "\n",
    "print filter(lambda col: len(set(securities[col]))==1, securities)\n",
    "print '\\n'\n",
    "print securities['SEC filings'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prob 2. Sampling\n",
    "\n",
    "#### Introduction \n",
    "(**You may skip and read the actual problem below**)<br>\n",
    "For each company, we would like to predict its <a href=https://en.wikipedia.org/wiki/Global_Industry_Classification_Standard target =_blank>GICS sector</a> (which is recorded in a column in the data frame <a href=https://graderdata.s3.amazonaws.com/securities.txt target=_blank>securities</a>) based on the <a href=https://graderdata.s3.amazonaws.com/fundamentals.txt>fundamentals</a>.\n",
    "\n",
    "For simplicity we clean the data with the following process:\n",
    "- Removed the columns with any missing value: `['Cash Ratio', 'Quick Ratio', 'Current Ratio', 'Estimated Shares Outstanding', 'Earnings Per Share', 'For Year']` from <a href=https://graderdata.s3.amazonaws.com/fundamentals.txt>fundamentals</a>.\n",
    "- Removed the column `Period End`, grouped the data by `Ticker Symbol` and then took the average of all the numerical columns from the data frame from the previous step.\n",
    "- Normalized the columns from the previous step.\n",
    "- Inserted the `GICS Sector` from <a href=https://graderdata.s3.amazonaws.com/securities.txt target=_blank>securities</a> to the data frame from the previous step.\n",
    "\n",
    "The resulted data frame is <a href =https://graderdata.s3.amazonaws.com/nyse_data.txt target=_blank>nyse_data</a>.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "#### Problem\n",
    "We would like to hold out part of the <a href =https://graderdata.s3.amazonaws.com/nyse_data.txt target=_blank>nyse_data</a> as the test dataset with the function `train_test_split`. We would like to:\n",
    "- hold out **20%** of the observations as test dataset. \n",
    "- make sure that the **distribution of the labels `y_train` and `y_test` to be as identical as possible**. \n",
    "\n",
    "Fill in the code below to split the data properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "nyse_data = pd.read_csv('https://graderdata.s3.amazonaws.com/nyse_data.csv', index_col=0)\n",
    "X = nyse_data.iloc[:,:-1]\n",
    "y = nyse_data.iloc[:,-1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    ### fill in your code here\n",
    "                                                    test_size=0.2, \n",
    "                                                    stratify=y,\n",
    "                                                    random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prob 3. Tune Random Forest Models\n",
    "\n",
    "With the training set and test set we obtained in the previous question, we would like to tune a random forest model to predict `GICS sector`. Fill the code below to test the parameters:\n",
    "\n",
    "- `max_depth: [10, 20]`\n",
    "- `n_estimators: [100, 500]`\n",
    "\n",
    "Tune the model and print the score on the test set.\n",
    "\n",
    "**Note**: You may assume that `X_train, X_test, y_train` and `y_test` have been created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.622222222222\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from numpy import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "nyse_data = pd.read_csv('https://graderdata.s3.amazonaws.com/nyse_data.csv', index_col=0)\n",
    "X = nyse_data.iloc[:,:-1]\n",
    "y = nyse_data.iloc[:,-1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    stratify=y,\n",
    "                                                    random_state=1)\n",
    "\n",
    "####### Your code here\n",
    "\n",
    "sk4 = StratifiedKFold()\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "### Create your grid here\n",
    "params =  {'max_depth':[10, 20],\n",
    "           'n_estimators': [100, 500]}\n",
    "\n",
    "### Your code here\n",
    "cv_rf = GridSearchCV(rf, param_grid=params, cv=sk4) \n",
    "cv_rf.fit(X_train, y_train)                         \n",
    "print cv_rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prob 4.  Lasso regression\n",
    "\n",
    "Again, we would like to predict its <a href=https://en.wikipedia.org/wiki/Global_Industry_Classification_Standard target =_blank>GICS sector</a> (which is recorded in a column in the data frame <a href=https://graderdata.s3.amazonaws.com/securities.txt target=_blank>securities</a>) based on the <a href=https://graderdata.s3.amazonaws.com/fundamentals.txt>fundamentals</a>.\n",
    "\n",
    "We train a lasso model with the penalty constant 10, as the code below. Which variables (there are more than one) eventually make no contribution to the prediction?\n",
    "\n",
    "**Note**: You may write the actual column names or write the code to return those columns as your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Long-Term Investments', 0.0),\n",
       " ('Other Current Liabilities', 0.0),\n",
       " ('Total Assets', 0.0),\n",
       " ('Total Liabilities & Equity', 0.0)]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "nyse_data = pd.read_csv('https://graderdata.s3.amazonaws.com/nyse_data.csv', index_col=0)\n",
    "X = nyse_data.iloc[:,:-1]; y = nyse_data.iloc[:,-1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    stratify=y,\n",
    "                                                    random_state=1)\n",
    "\n",
    "logit = LogisticRegression(penalty='l1', C=10)\n",
    "logit.fit(X_train, y_train)\n",
    "\n",
    "#sorted(zip(X.columns, np.sum(np.abs(logit.coef_), axis=0)), key=lambda x: -x[1])\n",
    "filter(lambda x: x[1]==0,\n",
    "       zip(X.columns, np.sum(np.abs(logit.coef_), axis=0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prob 5. PCA\n",
    "\n",
    "We would like to apply principal component analysis (pca) on the numerical columns of the <a href=https://graderdata.s3.amazonaws.com/fundamentals.txt>fundamentals dataset</a>. Again we remove categorical columns and the columns with missing values and then perform pca.\n",
    "\n",
    "We do it with the code below:\n",
    "```\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "%matplotlib inline\n",
    "\n",
    "fundamentals = pd.read_csv('https://graderdata.s3.amazonaws.com/fundamentals.csv',\n",
    "                           index_col=0).set_index('Ticker Symbol')\n",
    "to_be_removed = ['Period Ending','Cash Ratio', 'Quick Ratio', \n",
    "                 'Current Ratio', 'Estimated Shares Outstanding', \n",
    "                 'Earnings Per Share', 'For Year', '']\n",
    "X_train = fundamentals[filter(lambda col: col not in to_be_removed, fundamentals)]\n",
    "\n",
    "pca = PCA(n_components=10)\n",
    "pca.fit(X_train)\n",
    "plt.plot(range(10), pca.explained_variance_ratio_)\n",
    "```\n",
    "and we end up with:\n",
    "\n",
    "<img src=https://s3.amazonaws.com/graderdata/pca_not_normalized.png>\n",
    "\n",
    "Is there any problem with the steep drop in the ratio of variance explained? How could we modify it?\n",
    "\n",
    "\n",
    "- **A)** There is no problem.\n",
    "- **B)** There redundancy in the data is overwhelming. We should remove more columns before applying pca.\n",
    "- **C)** The missing values removed disturb the distribution of the data. We should impute the missing values instead.\n",
    "- **D)** The range of different columns vary too much. We should normalize/standardize before applying pca."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prob 6. Simple linear regression\n",
    "\n",
    "It seems reasonable that companies perform better in profit also perform better in stock price. We combine <a href=https://graderdata.s3.amazonaws.com/fundamentals.txt>fundamentals</a> and the <a href=https://graderdata.s3.amazonaws.com/prices-split-adjusted.txt>split adjusted price</a>. With some manipulation we obtain the data frame with `Return` and `Earnings Per Share` (EPS) for each stock in a particular period. Part of the data is as below:\n",
    "\n",
    "```\n",
    "                                  Return  Earnings Per Share\n",
    "symbol Period Start Period End                              \n",
    "AAL    2012-12-31   2013-12-31  0.003199              -11.25\n",
    "       2013-12-31   2014-12-31  0.004424                4.02\n",
    "       2014-12-31   2015-12-31 -0.000851               11.39\n",
    "AAP    2012-12-29   2013-12-28  0.002069                5.36\n",
    "       2013-12-28   2015-01-03  0.001750                6.75\n",
    "       2015-01-03   2016-01-02 -0.000152                6.45\n",
    "AAPL   2013-09-28   2014-09-27  0.001910                6.49\n",
    "       2014-09-27   2015-09-26  0.000581                9.28\n",
    "       2015-09-26   2016-09-24  0.000010                8.35\n",
    "```\n",
    "\n",
    "Fill the code below to regress the `Return` on `Earnings Per Share`  with `statsmodels`. \n",
    "- **Make sure you fit the intercept.** \n",
    "- Print out the summary of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 Return   R-squared:                       0.015\n",
      "Model:                            OLS   Adj. R-squared:                  0.014\n",
      "Method:                 Least Squares   F-statistic:                     17.05\n",
      "Date:                Mon, 29 May 2017   Prob (F-statistic):           3.91e-05\n",
      "Time:                        15:06:29   Log-Likelihood:                 6213.4\n",
      "No. Observations:                1146   AIC:                        -1.242e+04\n",
      "Df Residuals:                    1144   BIC:                        -1.241e+04\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "======================================================================================\n",
      "                         coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
      "--------------------------------------------------------------------------------------\n",
      "const                  0.0004   3.83e-05     10.686      0.000         0.000     0.000\n",
      "Earnings Per Share  2.649e-05   6.41e-06      4.129      0.000      1.39e-05  3.91e-05\n",
      "==============================================================================\n",
      "Omnibus:                      116.323   Durbin-Watson:                   2.069\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              245.046\n",
      "Skew:                           0.618   Prob(JB):                     6.15e-54\n",
      "Kurtosis:                       4.899   Cond. No.                         7.30\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "return_EPS = pd.read_csv('https://graderdata.s3.amazonaws.com/return_EPS.csv', index_col=[0, 1, 2])\n",
    "\n",
    "x = return_EPS[['Earnings Per Share']]\n",
    "y = return_EPS['Return']\n",
    "\n",
    "### Your code here\n",
    "x = sm.add_constant(x)\n",
    "model = sm.OLS(y, x)\n",
    "results = model.fit()\n",
    "print results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prob 7. KMeans\n",
    "\n",
    "With the numerical columns of the <a href =https://graderdata.s3.amazonaws.com/nyse_data.txt target=_blank>nyse_data</a> dataset, write code to perform KMeans clustering with 20 clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "    n_clusters=20, n_init=10, n_jobs=1, precompute_distances='auto',\n",
       "    random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "nyse_data = pd.read_csv('https://graderdata.s3.amazonaws.com/nyse_data.csv', index_col=0)\n",
    "X_train = nyse_data.iloc[:,:-1]\n",
    "\n",
    "#### Your code here\n",
    "k1 = KMeans(n_clusters=20)\n",
    "k1.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
